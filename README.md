## Image Understanding and Reasoning

| **Name**              | **Paper**                                                                                                                                                  | **Code**                                                                                                                                                                          | **Task**                                                                     | **Date**   |
| --------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------- | ---------- |
| R1-V                  | [RLVR in Vision Language Models: Findings, Questions and Directions](https://deepagent.notion.site/rlvr-in-vlms)                                           | [R1-V](https://github.com/Deep-Agent/R1-V)![Stars](https://img.shields.io/github/stars/Deep-Agent/R1-V?style=social)                                                              | Counting/Geometry Reasoning                                                  | 2025.02.15 |
| Visual-RFT            | [Visual Reinforcement Fine-Tuning](https://arxiv.org/pdf/2503.01785)                                                                                       | [Visual-RFT](https://github.com/Liuziyu77/Visual-RFT)![Stars](https://img.shields.io/github/stars/Liuziyu77/Visual-RFT?style=social)                                              | Classification/Detection/Grounding                                           | 2025.03.03 |
| VisualThinker-R1-Zero | [R1-Zero’s “Aha Moment” in Visual Reasoning on a 2B Non-SFT Model](https://arxiv.org/pdf/2503.05132)                                                       | [VisualThinker-R1-Zero](https://github.com/turningpoint-ai/VisualThinker-R1-Zero)![Stars](https://img.shields.io/github/stars/turningpoint-ai/VisualThinker-R1-Zero?style=social) | VQA (CVBench)                                                                | 2025.03.06 |
| Vision-R1             | [Vision-R1: Incentivizing Reasoning Capability in Multimodal Large Language Models](https://arxiv.org/abs/2503.06749)                                      | [Vision-R1](https://github.com/Osilly/Vision-R1)![Stars](https://img.shields.io/github/stars/Osilly/Vision-R1?style=social)                                                       | Math Reasoning                                                               | 2025.03.09 |
| MM-EUREKA             | [MM-Eureka: Exploring the Frontiers of Multimodal Reasoning with Rule-based Reinforcement Learning](https://arxiv.org/abs/2503.07365)                      | [MM-EUREKA](https://github.com/ModalMinds/MM-EUREKA)![Stars](https://img.shields.io/github/stars/ModalMinds/MM-EUREKA?style=social)                                               | Mathematical Reasoning/Multidisciplinary Reasoning                           | 2025.03.10 |
| Seg-Zero              | [Seg-Zero: Reasoning-Chain Guided Segmentation via Cognitive Reinforcement](https://arxiv.org/abs/2503.06520)                                              | [Seg-Zero](https://github.com/dvlab-research/Seg-Zero)![Stars](https://img.shields.io/github/stars/dvlab-research/Seg-Zero?style=social)                                          |                                                                              | 2025.03.10 |
| Curr-ReFT             | [Boosting the Generalization and Reasoning of Vision Language Models with Curriculum Reinforcement Learning](https://arxiv.org/abs/2503.07065)             | [Curr-ReFT](https://github.com/ding523/Curr_REFT)![Stars](https://img.shields.io/github/stars/ding523/Curr_REFT?style=social)                                                     |                                                                              | 2025.03.10 |
| LMM-R1                | [LMM-R1: Empowering 3B LMMs with Strong Reasoning Abilities Through Two-Stage Rule-Based RL](https://arxiv.org/pdf/2503.07536)                             | [LMM-R1](https://github.com/TideDra/lmm-r1)![Stars](https://img.shields.io/github/stars/TideDra/lmm-r1?style=social)                                                              |                                                                              | 2025.03.11 |
| R1-VL                 | [R1-VL: Learning to Reason with Multimodal Large Language Models via Step-wise Group Relative Policy Optimization](https://arxiv.org/pdf/2503.12937)       | [R1-VL](https://github.com/jingyi0000/R1-VL)![Stars](https://img.shields.io/github/stars/jingyi0000/R1-VL?style=social)                                                           | Math Reasoning/Chart Understanding/Visual Hallucination/Visual Understanding | 2025.03.17 |
| DeepPerception        | [DeepPerception: Advancing R1-like Cognitive Visual Perception in MLLMs for Knowledge-Intensive Visual Grounding](https://arxiv.org/pdf/2503.12797)        | [DeepPerception](https://github.com/thunlp/DeepPerception)![Stars](https://img.shields.io/github/stars/thunlp/DeepPerception?style=social)                                        | Knowledge-intensive Visual Grounding                                         | 2025.03.18 |
| R1-Onevision          | [R1-Onevision: Advancing Generalized Multimodal Reasoning through Cross-Modal Formalization](https://arxiv.org/pdf/2503.10615)                             | [R1-Onevision](https://github.com/Fancy-MLLM/R1-Onevision)![Stars](https://img.shields.io/github/stars/Fancy-MLLM/R1-Onevision?style=social)                                      | Natural Scenes/Science/ Math/ OCR/Chart/Screen                               | 2025.03.18 |
| OThink-MR1            | [OThink-MR1: Stimulating multimodal generalized reasoning capabilities via dynamic reinforcement learning](https://arxiv.org/abs/2503.16081)               |                                                                                                                                                                                   |                                                                              | 2025.03.20 |
| Think or Not Think    | [Think or Not Think: A Study of Explicit Thinking in Rule-Based Visual Reinforcement Fine-Tuning](https://arxiv.org/abs/2503.16188)                        | [Think or Not Think](https://github.com/minglllli/CLS-RL)![Stars](https://img.shields.io/github/stars/minglllli/CLS-RL?style=social)                                              |                                                                              | 2025.03.20 |
| OpenVLThinker         | [OpenVLThinker: An Early Exploration to Complex Vision-Language Reasoning via Iterative Self-Improvement](https://arxiv.org/pdf/2503.17352)                | [OpenVLThinker](https://github.com/yihedeng9/OpenVLThinker)![Stars](https://img.shields.io/github/stars/yihedeng9/OpenVLThinker?style=social)                                     | Math Reasoning                                                               | 2025.03.21 |
| Reason-RFT            | [Reason-RFT: Reinforcement Fine-Tuning for Visual Reasoning](https://arxiv.org/abs/2503.20752)                                                             | [Reason-RFT](https://github.com/tanhuajie/Reason-RFT)![Stars](https://img.shields.io/github/stars/tanhuajie/Reason-RFT?style=social)                                              |                                                                              | 2025.03.26 |
| Q-Insight             | [Q-Insight: Understanding Image Quality via Visual Reinforcement Learning](https://arxiv.org/abs/2503.22679)                                               | [Q-Insight](https://github.com/lwq20020127/Q-Insight)![Stars](https://img.shields.io/github/stars/lwq20020127/Q-Insight?style=social)                                             |                                                                              | 2025.03.28 |
| Hint-GRPO             | [Boosting MLLM Reasoning with Text-Debiased Hint-GRPO](https://arxiv.org/pdf/2503.23905)                                                                   |                                                                                                                                                                                   | Mathematical Reasoning/Universal Multimodal Reasoning                        | 2025.03.31 |
| CrowdVLM-R1           | [CrowdVLM-R1: Expanding R1 Ability to Vision Language Model for Crowd Counting using Fuzzy Group Relative Policy Reward](https://arxiv.org/abs/2504.03724) | [CrowdVLM-R1](https://github.com/yeyimilk/CrowdVLM-R1)![Stars](https://img.shields.io/github/stars/yeyimilk/CrowdVLM-R1?style=social)                                             |                                                                              | 2025.03.31 |
| Skywork R1V           | [Skywork R1V: Pioneering Multimodal Reasoning with Chain-of-Thought](https://arxiv.org/abs/2504.05599)                                                     | [Skywork R1V](https://github.com/SkyworkAI/Skywork-R1V/tree/main)![Stars](https://img.shields.io/github/stars/SkyworkAI/Skywork-R1V?style=social)                                 |                                                                              | 2025.04.08 |
| VLAA-Thinking         | [SFT or RL? An Early Investigation into Training R1-Like Reasoning Large Vision-Language Models](https://arxiv.org/pdf/2504.11468)                         | [VLAA-Thinking](https://github.com/UCSC-VLAA/VLAA-Thinking)![Stars](https://img.shields.io/github/stars/UCSC-VLAA/VLAA-Thinking?style=social)                                     |                                                                              | 2025.04.10 |
| VLM-R1                | [VLM-R1: A Stable and Generalizable R1-style Large Vision-Language Model](https://arxiv.org/abs/2504.07615)                                                | [VLM-R1](https://github.com/om-ai-lab/VLM-R1)![Stars](https://img.shields.io/github/stars/om-ai-lab/VLM-R1?style=social)                                                          |                                                                              | 2025.04.10 |
| ThinkLite-VL          | [SoTA with Less: MCTS-Guided Sample Selection for Data-Efficient Visual Reasoning Self-Improvement](https://arxiv.org/abs/2504.07934)                      | [ThinkLite-VL](https://github.com/si0wang/ThinkLite-VL)![Stars](https://img.shields.io/github/stars/si0wang/ThinkLite-VL?style=social)                                            |                                                                              | 2025.04.10 |
| Perception-R1         | [Perception-R1: Pioneering Perception Policy with Reinforcement Learning](https://arxiv.org/abs/2504.07954)                                                | [Perception-R1](https://github.com/linkangheng/PR1)![Stars](https://img.shields.io/github/stars/linkangheng/PR1?style=social)                                                     |                                                                              | 2025.04.10 |
|                       |                                                                                                                                                            |                                                                                                                                                                                   |                                                                              |            |

[Visual-RFT](https://github.com/Liuziyu77/Visual-RFT)![Stars](https://img.shields.io/github/stars/Liuziyu77/Visual-RFT?style=social)
## Omni
| **Name** | **Paper**                                                                                                                | **Code**                                                                                                                    | **Task**            | **Date**   |
| -------- | ------------------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------- | ------------------- | ---------- |
| R1-Omni  | [R1-Omni: Explainable Omni-Multimodal Emotion Recognition with Reinforcement Learning](https://arxiv.org/pdf/2503.05379) | [R1-Omni](https://github.com/HumanMLLM/R1-Omni)![Stars](https://img.shields.io/github/stars/HumanMLLM/R1-Omni?style=social) | Emotion Recognition | 2025.03.10 |
## Medical
| **Name**   | **Paper**                                                                                                                                             | **Code**                                                              | **Task**       | **Date**   |
| ---------- | ----------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------- | -------------- | ---------- |
| MedVLM-R1  | [MedVLM-R1: Incentivizing Medical Reasoning Capability of Vision-Language Models (VLMs) via Reinforcement Learning](https://arxiv.org/pdf/2502.19634) | [MedVLM-R1(huggingface)](https://huggingface.co/JZPeterPan/MedVLM-R1) | MedAgentsBench | 2025.03.07 |
| GMAI-VL-R1 | [GMAI-VL-R1: Harnessing Reinforcement Learning for Multimodal Medical Reasoning](https://arxiv.org/abs/2504.01886)                                    |                                                                       |                | 2025.04.02 |
| PathVLM-R1 | [PathVLM-R1: A Reinforcement Learning-Driven Reasoning Model for Pathology Visual-Language Tasks](https://arxiv.org/abs/2504.09258)                   |                                                                       |                |            |
## Autonomous Driving
| **Name**   | **Paper**                                                                                                                                   | **Code**                                                                                                                       | **Task** | **Date**   |
| ---------- | ------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------ | -------- | ---------- |
| AlphaDrive | [AlphaDrive: Unleashing the Power of VLMs in Autonomous Driving via Reinforcement Learning and Reasoning](https://arxiv.org/abs/2503.07608) | [AlphaDrive](https://github.com/hustvl/AlphaDrive)![Stars](https://img.shields.io/github/stars/hustvl/AlphaDrive?style=social) | MetaAD   | 2025.03.07 |
## GUI
| **Name** | **Paper**                                                                                                      | **Code**                                                                                                               | **Task** | **Date**   |
| -------- | -------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------- | -------- | ---------- |
| GUI-R1   | [GUI-R1 : A Generalist R1-Style Vision-Language Action Model For GUI Agents](https://arxiv.org/abs/2504.10458) | [GUI-R1](https://github.com/ritzz-ai/GUI-R1)![Stars](https://img.shields.io/github/stars/ritzz-ai/GUI-R1?style=social) |          | 2025.04.14 |
|          |                                                                                                                |                                                                                                                        |          |            |
|          |                                                                                                                |                                                                                                                        |          |            |
## Others
| **Name**    | **Paper**                                                                                                                     | **Code** | **Task** | **Date**   |
| ----------- | ----------------------------------------------------------------------------------------------------------------------------- | -------- | -------- | ---------- |
| VLMGuard-R1 | [VLMGuard-R1: Proactive Safety Alignment for VLMs via Reasoning-Driven Prompt Optimization](https://arxiv.org/abs/2504.12661) |          |          | 2025.04.17 |
## Related Awesome Lists

- [Awesome-Multimodal-Reasoning](https://github.com/Video-R1/Awesome-Multimodal-Reasoning)
- [Awesome-RL-based-Reasoning-MLLMs](https://github.com/Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs)
- [Awesome-Large-Multimodal-Reasoning-Models](https://github.com/HITsz-TMG/Awesome-Large-Multimodal-Reasoning-Models)
